{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro To Scikit-learn\n",
    "\n",
    "Normal workflow:\n",
    "\n",
    "1. Get Data Ready\n",
    "2. Pick a model that suits the problem\n",
    "3. Fit the model to the data and make a prediction\n",
    "4. Evaluate the model\n",
    "5. Improve through experimentation\n",
    "6. Save and reload the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Quick Preview of Entire Workflow!\n",
    "\n",
    "### 1. Get the Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data and see what it looks like\n",
    "heart_disease = pd.read_csv('data/heart-disease.csv')\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to have the model guess `target` is 1 or 0, so we need variables\n",
    "# Create X (features matrix)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (labels)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pick a model and hyperparameters that fit the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import classification model from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier # Can classify data (1 or 0)\n",
    "clf = RandomForestClassifier() # clf = classifier \n",
    "\n",
    "## Keep default hyperparameters\n",
    "clf.get_params() # see model's hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit the model to the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X (features) and y (labels) into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # test_size is % of rows that go into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell sklearn to fit to the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a predictions on the test set\n",
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well has model predicted data on the training set?\n",
    "clf.score(X_train, y_train) # 1.0 makes sense because it was trained on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032786885245902"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well has the model predicted data on the test set?\n",
    "clf.score(X_test, y_test) # output should probably be different from training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77        27\n",
      "           1       0.81      0.85      0.83        34\n",
      "\n",
      "    accuracy                           0.80        61\n",
      "   macro avg       0.80      0.80      0.80        61\n",
      "weighted avg       0.80      0.80      0.80        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use some other measure to check the model's accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  7],\n",
       "       [ 5, 29]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032786885245902"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Improve the Model\n",
    "\n",
    "Models can be improved by experimenting with tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model Accuracy on test set: 83.61%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model Accuracy on test set: 83.61%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model Accuracy on test set: 81.97%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model Accuracy on test set: 85.25%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model Accuracy on test set: 80.33%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model Accuracy on test set: 83.61%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model Accuracy on test set: 81.97%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model Accuracy on test set: 83.61%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model Accuracy on test set: 83.61%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try different amount of n_estimators\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model Accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save and Load Models\n",
    "Use Python's pickle library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump saves the model\n",
    "# pass in the instantiated sklearn model object\n",
    "# \"wb\" means write binary, or write the file contents\n",
    "pickle.dump(clf, open(\"models/heart-disease-random-forest.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"rb\" means read binary\n",
    "loaded_model = pickle.load(open(\"models/heart-disease-random-forest.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# In-Depth Sections\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting the Data Ready\n",
    "---\n",
    "\n",
    "For the below steps, it's important to **run data transformations separately for training and testing sets**\n",
    "\n",
    "Three main things to do:\n",
    "- Split the data into features and labels (usually `X` and `y`)\n",
    "- Split data into training and test sets (maybe 20% of data in test set)\n",
    "- Filling (also called **imputing**) or disregarding missing values\n",
    "- Converting non-numerical values to numerical values (AKA **feature encoding**)\n",
    "- (Optional) Reduce the amount of data you use in the model\n",
    "  - Also called **Dimensionality** reduction or column reduction\n",
    "  - This can help save compute time and money by getting rid of data that might not be useful\n",
    "- (Optional) **Feature Scaling** to make sure all the data is on the same scale so the ML model can find patterns. There are two main ways of doing this:\n",
    "  - **Normalization (min-max scaling)**: Rescales all numerical values to be between 0 and 1. Scikit-learn has a library for this in the [MinMaxScalar class](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "  - **Standardization**: Subtracts the mean value from all features and then scales them by unit variance. Scikit-learn has a library for this in the [StandardScalar class](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "  - Feature Scaling usually isn't required for your target variable\n",
    "  - Feature scaling is not usually required with tree-based models (random forest) since they can handle varying features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still have this imported\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Split into Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features do not include `target` column, which is whether or not the person has heart disease\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label is the 'target' column\n",
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Check shapes of data sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Convert All Data to Be Numeric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,\n",
       "      Make Colour  Odometer (KM)  Doors  Price\n",
       " 0   Honda  White          35431      4  15323\n",
       " 1     BMW   Blue         192714      5  19943\n",
       " 2   Honda  White          84714      4  28343\n",
       " 3  Toyota  White         154365      4  13434\n",
       " 4  Nissan   Blue         181577      3  14043)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need data that has non-numeric data so we can practice changing it\n",
    "car_sales = pd.read_csv(\"data/car-sales-extended.csv\")\n",
    "len(car_sales), car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             object\n",
       "Colour           object\n",
       "Odometer (KM)     int64\n",
       "Doors             int64\n",
       "Price             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See that data is not in all numerics\n",
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the non-numeric categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Separate into X (features) and y (labels)\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "# Prepare which features in your data are categorical and need to be transformed\n",
    "# Note: \"Doors\" is categorical because you could split the data into groups by # of doors\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "\n",
    "# Setup OneHotEncoder (see explanation below)\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Setup transformer\n",
    "# Tell it to use \"one_hot\" method with the one_hot object we created, and use it on the categorical_features we created\n",
    "# Tell it to \"passthrough\" (skip, not tranform) columns that are already numeric\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "# Fit tranformed data\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoder\n",
    "\n",
    "One Hot Encoder takes a single column that has categorical data in it, creates a new column for each unique category, and puts the data back into the data with a 1 in the unique column where it has a matching category. Here's an example graphic:\n",
    "\n",
    "![](../images/one-hot-encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11        12\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   35431.0\n",
       "1    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  192714.0\n",
       "2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   84714.0\n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  154365.0\n",
       "4    0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  181577.0\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
       "995  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   35820.0\n",
       "996  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  155144.0\n",
       "997  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   66604.0\n",
       "998  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  215883.0\n",
       "999  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  248360.0\n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See transformed data in Pandas DataFrame\n",
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another Way to Convert with Pandas\n",
    "\n",
    "This might not work on categorical data that is already in the form of numbers (like Doors in our example), but pandas does more intelligently name the columns so you can see what OneHotEncoding is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doors</th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doors  Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0        4         0           1            0            0             0   \n",
       "1        5         1           0            0            0             0   \n",
       "2        4         0           1            0            0             0   \n",
       "3        4         0           0            0            1             0   \n",
       "4        3         0           0            1            0             0   \n",
       "..     ...       ...         ...          ...          ...           ...   \n",
       "995      4         0           0            0            1             1   \n",
       "996      3         0           0            1            0             0   \n",
       "997      4         0           0            1            0             0   \n",
       "998      4         0           1            0            0             0   \n",
       "999      4         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  \n",
       "0              0             0           0             1  \n",
       "1              1             0           0             0  \n",
       "2              0             0           0             1  \n",
       "3              0             0           0             1  \n",
       "4              1             0           0             0  \n",
       "..           ...           ...         ...           ...  \n",
       "995            0             0           0             0  \n",
       "996            0             0           0             1  \n",
       "997            1             0           0             0  \n",
       "998            0             0           0             1  \n",
       "999            1             0           0             0  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2364711420373471"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to fit the model with converted data\n",
    "np.random.seed(24)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "\n",
    "# Build and train model to predict car price\n",
    "from sklearn.ensemble import RandomForestRegressor # Can predict a number (regression line)\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Handle Missing Values in Data\n",
    "\n",
    "Two main ways to deal with missing values:\n",
    "1. Fill them with some other value (**imputation**)\n",
    "2. Remove the samples with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some data that has missing values\n",
    "car_sales_missing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas fills missing values with `NaN`, so we can check if any of those exist\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 - Fill Missing Data With Values (Imputation)\n",
    "Pandas has ways to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              0\n",
       "Colour            0\n",
       "Odometer (KM)     0\n",
       "Doors             0\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Odometer (KM)\" column with mean of entire data set\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "\n",
    "# Fill the \"Doors\" column (assumption that average car has 4 doors)\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)\n",
    "\n",
    "# Check dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Remove Missing Data Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with NaN values\n",
    "# At this point there are only Price values missing. Since that's the target label, we don't\n",
    "# necessarily want to try to fill it with other data\n",
    "car_sales_missing.dropna(inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resplit the data now that NaN values are gone\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "\n",
    "# Turn the non-numeric categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Prepare which features in your data are categorical and need to be transformed\n",
    "# Note: \"Doors\" is categorical because you could split the data into groups by # of doors\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "\n",
    "# Setup OneHotEncoder (see explanation below)\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Setup transformer\n",
    "# Tell it to use \"one_hot\" method with the one_hot object we created, and use it on the categorical_features we created\n",
    "# Tell it to \"passthrough\" (skip, not tranform) columns that are already numeric\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "# Fit tranformed data\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Filling Missing Values With Only Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Make Colour  Odometer (KM)  Doors    Price\n",
       " 0   Honda  White        35431.0    4.0  15323.0\n",
       " 1     BMW   Blue       192714.0    5.0  19943.0\n",
       " 2   Honda  White        84714.0    4.0  28343.0\n",
       " 3  Toyota  White       154365.0    4.0  13434.0\n",
       " 4  Nissan   Blue       181577.0    3.0  14043.0,\n",
       " Make             49\n",
       " Colour           50\n",
       " Odometer (KM)    50\n",
       " Doors            50\n",
       " Price            50\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reimport data so we have the missing values\n",
    "car_sales_missing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head(), car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows that are missing \"Price\" since that's our target label and we don't want to guess at that\n",
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Honda', 'White', 4.0, 35431.0],\n",
       "       ['BMW', 'Blue', 5.0, 192714.0],\n",
       "       ['Honda', 'White', 4.0, 84714.0],\n",
       "       ...,\n",
       "       ['Nissan', 'Blue', 4.0, 66604.0],\n",
       "       ['Honda', 'White', 4.0, 215883.0],\n",
       "       ['Toyota', 'Blue', 4.0, 248360.0]], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values with Scikit-learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with 'missing' and numerical values with mean\n",
    "# Create imputer object with \"constant\" (always same) strategy and the value to fill it with\n",
    "categorical_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "\n",
    "# \"Doors\" label is categorical but technically stored as numerical, so we make a special imputer for it\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "\n",
    "# Create an imputer to fill the missing numerical values with the mean\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define column names\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "door_features = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer to fill the missing values\n",
    "# ColumnTransformer takes 3-tuples of imputer name, imputer object, column names\n",
    "imputer = ColumnTransformer([\n",
    "    (\"categorical_imputer\", categorical_imputer, categorical_features),\n",
    "    (\"door_imputer\", door_imputer, door_features),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])\n",
    "\n",
    "# Tranform the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Make Colour Doors Odometer (KM)\n",
       " 0   Honda  White   4.0       35431.0\n",
       " 1     BMW   Blue   5.0      192714.0\n",
       " 2   Honda  White   4.0       84714.0\n",
       " 3  Toyota  White   4.0      154365.0\n",
       " 4  Nissan   Blue   3.0      181577.0,\n",
       " Make             0\n",
       " Colour           0\n",
       " Doors            0\n",
       " Odometer (KM)    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all values were filled by putting it into a Pandas DataFrame\n",
    "car_sales_filled = pd.DataFrame(filled_X, columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled.head(), car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<950x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the non-numeric categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Prepare which features in your data are categorical and need to be transformed\n",
    "# Note: \"Doors\" is categorical because you could split the data into groups by # of doors\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "\n",
    "# Setup OneHotEncoder (see explanation below)\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Setup transformer\n",
    "# Tell it to use \"one_hot\" method with the one_hot object we created, and use it on the categorical_features we created\n",
    "# Tell it to \"passthrough\" (skip, not tranform) columns that are already numeric\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "# Fit tranformed data\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21990196728583944"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have the data as all numbers and with filled values\n",
    "# Let's fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing the Right Estimator/Algorithm For Your Problem\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to note:\n",
    "- SKlearn refers to machine learning models and algorithms as **estimators**\n",
    "- Classification problem - predicting a category (hearth disease or not)\n",
    "  - Sometimes you'll see `clf` (short for classifier) used as a classification estimator\n",
    "- Regression Problem - predicting a number (selling price of a car)\n",
    "\n",
    "[SKlearn has a map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) of what kind of model you should maybe look at using:\n",
    "![](../images/ml_map.png)\n",
    "\n",
    "**NOTE** - Some generalized tips:\n",
    "\n",
    "1. If you have structured (tabled) data, use Ensemble methods\n",
    "2. If you have unstructured data, use deep learning or transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Picking a Machine Learning Model for a Regression Problem\n",
    "\n",
    "Using the [California Housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nAn household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surpinsingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get California Housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn into Pandas DataFrame so it's easier to visualize\n",
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  target  \n",
       "0        -122.23   4.526  \n",
       "1        -122.22   3.585  \n",
       "2        -122.24   3.521  \n",
       "3        -122.25   3.413  \n",
       "4        -122.25   3.422  \n",
       "...          ...     ...  \n",
       "20635    -121.09   0.781  \n",
       "20636    -121.21   0.771  \n",
       "20637    -121.22   0.923  \n",
       "20638    -121.32   0.847  \n",
       "20639    -121.24   0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add target column onto dataframe\n",
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758549611440128"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import algorithm\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model \n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model on (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if `Ridge` didn't work or didn't fit our needs?\n",
    "\n",
    "We can try a different model from the scikit-learn algorithm map\n",
    "\n",
    "Let's try an [Ensemble Model](https://scikit-learn.org/stable/modules/ensemble.html) (combination of smaller models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065734772187598"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestRegressor from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create random forest model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Picking a Machine Learning Model on a Classification Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a classification problem data set\n",
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulting the map says to try `LinearSVC`, so let's do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repos\\ml-ds\\learning-projects\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8688524590163934"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = LinearSVC(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try RandomForestClassifier as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the RandomForestClassifier\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the Model to the Data and Make Predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Fitting the Model to the Data\n",
    "\n",
    "Different names for:\n",
    "- X = features, feature variables, data\n",
    "- y = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit the model to the data (training ML model)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the RandomForestClassifier (use the patterns the ML model has found)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Making Predictions With ML Model\n",
    "\n",
    "Two main ways to make predictions:\n",
    "- predict()\n",
    "- predict_proba()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 `Using predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16000/1272494838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Use a trained model to make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# this doesn't work because the array doesn't match the data the model trained on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Use a trained model to make predictions\n",
    "model.predict(np.array[1, 7, 8, 3, 4]) # this doesn't work because the array doesn't match the data the model trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       " 179   57    1   0       150   276    0        0      112      1      0.6   \n",
       " 228   59    1   3       170   288    0        0      159      0      0.2   \n",
       " 111   57    1   2       150   126    1        1      173      0      0.2   \n",
       " 246   56    0   0       134   409    0        0      150      1      1.9   \n",
       " 60    71    0   2       110   265    1        0      130      0      0.0   \n",
       " \n",
       "      slope  ca  thal  \n",
       " 179      1   1     1  \n",
       " 228      1   0     3  \n",
       " 111      2   1     3  \n",
       " 246      1   2     3  \n",
       " 60       2   1     2  ,\n",
       " (61, 13))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(), X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions from test split\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual test labels\n",
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare predictions to truth labels to evaluate the model\n",
    "y_preds = model.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That comparison is the same as the built-in score function\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to do it\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Using `predict_proba()`\n",
    "`predict_proba()` returns probabilities of a classification label\n",
    "\n",
    "In the example of the heart disease data we're using, the two classes are 0 (does not have heart disease) and 1 (has heart disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.49, 0.51],\n",
       "       [0.43, 0.57],\n",
       "       [0.84, 0.16],\n",
       "       [0.18, 0.82]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what it puts out\n",
    "model.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's predict() on the same data\n",
    "model.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above outputs are showing that the first five rows were put into the following classes with a certain probability. Index 0 was classified as 0 (no heart disease) with 89% probability of being correct and 11% of being wrong\n",
    "\n",
    "You can see that `predict_proba()` to see which predictions the model was very confident in and which it wasn't. Using `predict()` forces the model to make a classification prediction, but it could only be 51% probable and that might be something to look at\n",
    "\n",
    "`predict()` can also be used on Regression data. It'll make a prediction of a numerical value that you can compare to the test data. See below for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create model instance\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.49384  , 0.75494  , 4.9285964, 2.54316  , 2.33176  , 1.6525301,\n",
       "        2.34323  , 1.66182  , 2.47489  , 4.8344779]),\n",
       " array([0.477  , 0.458  , 5.00001, 2.186  , 2.78   , 1.587  , 1.982  ,\n",
       "        1.575  , 3.4    , 4.466  ]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare predictions to actual values\n",
    "y_preds[:10], np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32659871732073664"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical Evaluation of predictions compared to truth\n",
    "# Using Mean Absolute Error (average amount +/- the prediction was off the truth)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 main ways to evaluate a Scikit-learn model/estimator:\n",
    "- Estimator's built-in `score()` method\n",
    "  - For Classification problems, `score()` gives a percent accuracy\n",
    "  - For Regression problems, `score()` returns the Coefficient of Determination (r-squared)\n",
    "- The `scoring` parameter\n",
    "- Problem-specific metric functions\n",
    "\n",
    "Read more about them [here](https://scikit-learn.org/stable/modules/model_evaluation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Evaluation With `score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit the model to the data (training ML model)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the RandomForestClassifier (use the patterns the ML model has found)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See score on training data (expecting 1.0 since it saw the data)\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluation With `scoring` Parameter\n",
    "\n",
    "#### Cross Validation\n",
    "\n",
    "Cross Validation trains the model multiple times with different groups of train/test splits. In Scikit-learn, it defaults to using 5 different versions. This is `5-Fold Cross Validation`, but generalizing the concept is referred to as `k-Fold Cross Validation`\n",
    "\n",
    "![](../images/sklearn-cross-validation.png)\n",
    "\n",
    "Cross validation is a good way to check and make sure that your model is accurate and not just getting lucky with some really good train/test data. It can be a good measure to see how your model will react to real-world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score # import cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90322581, 0.83870968, 0.87096774, 0.9       , 0.86666667,\n",
       "       0.8       , 0.76666667, 0.83333333, 0.73333333, 0.83333333])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show cross validation scores (default is 5, can adjust with cv=#)\n",
    "cross_val_score(model, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8248087431693989)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "model_single_score = model.score(X_test, y_test)\n",
    "\n",
    "# Take the mean of 5-fold cross-validation scores\n",
    "model_cross_val_score = np.mean(cross_val_score(model, X, y, cv=5))\n",
    "\n",
    "# Compare the scores\n",
    "model_single_score, model_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.90163934, 0.83606557, 0.78333333, 0.78333333])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating a model with Cross Validation and Scoring Parameter\n",
    "# Scoring parameter set to None by default. It will use the passed model's default scoring parameter\n",
    "np.random.seed(42)\n",
    "cross_val_score(model, X, y, cv=5, scoring=None) # could do something like scoring=\"precision\" or \"recall\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated precision is 0.8248087431693989%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The cross-validated precision is {model_cross_val_score}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Classification Model Evaluation Metrics\n",
    "\n",
    "1. Accuracy\n",
    "2. Area Under ROC Curve\n",
    "3. Confusion Matrix\n",
    "4. Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "cvs = cross_val_score(clf, X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248087431693989"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Classifier Cross-Validated Accuracy: 82.48%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cvs) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Area Under ROC (Receiver Operating Characteristic) Curve\n",
    "\n",
    "Also sometimes referred to as AUC (area under curve). ROC curves are a comparison of a model's true positive rate (tpr) versus a model's false positive rate (fpr)\n",
    "\n",
    "**True positive**: Model predicts 1 when truth is 1\n",
    "\n",
    "**False Positive**: Model predicts 1 when truth is 0\n",
    "\n",
    "**True Negative**: Model predicts 0 when truth is 0\n",
    "\n",
    "**False Negative**: Model predicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.58, 0.42],\n",
       "        [0.09, 0.91],\n",
       "        [0.55, 0.45],\n",
       "        [0.75, 0.25],\n",
       "        [0.52, 0.48],\n",
       "        [0.09, 0.91],\n",
       "        [0.3 , 0.7 ],\n",
       "        [0.98, 0.02],\n",
       "        [0.14, 0.86],\n",
       "        [0.39, 0.61]]),\n",
       " 61)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Fit Classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "y_probs[:10], len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42, 0.91, 0.45, 0.25, 0.48, 0.91, 0.7 , 0.02, 0.86, 0.61])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs_positive = y_probs[:, 1] # Get column 1 from every row\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.03448276, 0.03448276, 0.03448276,\n",
       "       0.03448276, 0.03448276, 0.06896552, 0.06896552, 0.10344828,\n",
       "       0.10344828, 0.10344828, 0.13793103, 0.13793103, 0.17241379,\n",
       "       0.17241379, 0.20689655, 0.24137931, 0.24137931, 0.27586207,\n",
       "       0.27586207, 0.31034483, 0.34482759, 0.34482759, 0.44827586,\n",
       "       0.44827586, 0.51724138, 0.5862069 , 0.5862069 , 0.75862069,\n",
       "       0.89655172, 0.93103448, 1.        ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate fpr, tpr, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "# Check the false positive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots the ROC curve given the false positive rate (fpr)\n",
    "    and true positive rate (tpr) of a model\n",
    "    \"\"\"\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "\n",
    "    # Plot line with noe predictive power\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8561422413793104"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 Confusion Matrix\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict, giving you an idea about where the model is getting confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  5],\n",
       "       [ 8, 24]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial confusion matrix values\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Labels   0   1\n",
       "Actual Label            \n",
       "0                 24   5\n",
       "1                  8  24"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize confusion matrix with pd.crosstab()\n",
    "pd.crosstab(y_test, y_preds, rownames=[\"Actual Label\"], colnames=[\"Predicted Labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Repos\\ml-ds\\learning-projects\\env\n",
      "\n",
      "  added / updated specs:\n",
      "    - seaborn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    seaborn-0.11.2             |     pyhd3eb1b0_0         218 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         218 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  seaborn            pkgs/main/noarch::seaborn-0.11.2-pyhd3eb1b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "seaborn-0.11.2       | 218 KB    |            |   0% \n",
      "seaborn-0.11.2       | 218 KB    | 7          |   7% \n",
      "seaborn-0.11.2       | 218 KB    | ########## | 100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "seaborn-0.11.2       | 218 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "# Install Seaborn (a Conda package) into the current Conda environment from the Jupyter Notebook\n",
    "import sys\n",
    "!conda install --yes --prefix  {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make our confusion matrix more visual with Seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plot it using Seaborn\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix with Built-In Scikit-Learn 1.0\n",
    "There is new functionality to display a confusion matrix built into Scikit-learn 1.0, so let's see how to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x16e1ffbcaf0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x16e1ffbca30>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 Classification Report\n",
    "\n",
    "It's called a report because it reports multiple metrics\n",
    "\n",
    "**Precision**: Indicates the proportion of positive classifications which were actually correct\n",
    "\n",
    "**Recall**: Indicates the proportion of actual positives which were correctly predicted\n",
    "\n",
    "**F1 Score**: A combination of precision and recall\n",
    "\n",
    "**Support**: The number of samples each metric was calculated on\n",
    "\n",
    "**Accuracy**: The accuracy of the model in decimal form\n",
    "\n",
    "**Macro avg**: Average precision, recall, and F1 score between classes. This doesn't imbalance into effort, so pay attention if you have class imbalances\n",
    "  - Class imbalance referring to large differences in the number of samples in each classification\n",
    "\n",
    "**Weighted avg**: Weighted (with respect to how many samples are in each) average of precision, recall, and F1 score between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79        29\n",
      "           1       0.83      0.75      0.79        32\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.79      0.79      0.79        61\n",
      "weighted avg       0.79      0.79      0.79        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evalute model with Scikit-learn imported functions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repos\\ml-ds\\learning-projects\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Repos\\ml-ds\\learning-projects\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Repos\\ml-ds\\learning-projects\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.99985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.0  1.0  accuracy     macro avg  weighted avg\n",
       "precision     0.99990  0.0    0.9999      0.499950       0.99980\n",
       "recall        1.00000  0.0    0.9999      0.500000       0.99990\n",
       "f1-score      0.99995  0.0    0.9999      0.499975       0.99985\n",
       "support    9999.00000  1.0    0.9999  10000.000000   10000.00000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where precision and recall become valuable\n",
    "# Disease where 1/10,000 have it, build model to predict it\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one positive case\n",
    "\n",
    "disease_preds = np.zeros(10000) # Model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true, disease_preds, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Regression Model Evaluation Metrics\n",
    "\n",
    "1. R^2 (r-squared) Score or Coefficient of Determination\n",
    "   1. Similar to accuracy. Gives a quick indication, but doesn't show how wrong the model is for each incorrect prediction\n",
    "2. Mean Absolute Error (MAE)\n",
    "   1. Gives better indication of how far off each prediction is on average\n",
    "3. Mean Squared Error (MSE)\n",
    "   1. Similar to MAE, but since it's squared it amplifies large differences. If MAE is 200 and MSE is 200, the MSE 200 is indicating a much larger difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup data for regression model exploration\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 R Squared Score\n",
    "\n",
    "The proportion of the variation in the dependent variable that is predictable from the independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065734772187598"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since RandomForestRegressor is a regression model, its default score() returns r2\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065734772187598"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way using the r2_score metric function\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Get predictions\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "r2_score(y_true=y_test, y_pred=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Mean Absolute Error (MAE)\n",
    "\n",
    "Average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your model's predictions are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32659871732073664"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual values</th>\n",
       "      <th>predicted values</th>\n",
       "      <th>differences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>0.47700</td>\n",
       "      <td>0.493840</td>\n",
       "      <td>0.016840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>0.45800</td>\n",
       "      <td>0.754940</td>\n",
       "      <td>0.296940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>5.00001</td>\n",
       "      <td>4.928596</td>\n",
       "      <td>0.071414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>2.18600</td>\n",
       "      <td>2.543160</td>\n",
       "      <td>0.357160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>2.78000</td>\n",
       "      <td>2.331760</td>\n",
       "      <td>0.448240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13311</th>\n",
       "      <td>1.58700</td>\n",
       "      <td>1.652530</td>\n",
       "      <td>0.065530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>1.98200</td>\n",
       "      <td>2.343230</td>\n",
       "      <td>0.361230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>1.57500</td>\n",
       "      <td>1.661820</td>\n",
       "      <td>0.086820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>3.40000</td>\n",
       "      <td>2.474890</td>\n",
       "      <td>0.925110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>4.46600</td>\n",
       "      <td>4.834478</td>\n",
       "      <td>0.368478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual values  predicted values  differences\n",
       "20046        0.47700          0.493840     0.016840\n",
       "3024         0.45800          0.754940     0.296940\n",
       "15663        5.00001          4.928596     0.071414\n",
       "20484        2.18600          2.543160     0.357160\n",
       "9814         2.78000          2.331760     0.448240\n",
       "13311        1.58700          1.652530     0.065530\n",
       "7113         1.98200          2.343230     0.361230\n",
       "7668         1.57500          1.661820     0.086820\n",
       "18246        3.40000          2.474890     0.925110\n",
       "5723         4.46600          4.834478     0.368478"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize what MAE means\n",
    "df = pd.DataFrame(data={\"actual values\": y_test, \"predicted values\": y_preds})\n",
    "\n",
    "df[\"differences\"] = np.abs(df[\"predicted values\"] - df[\"actual values\"])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32659871732073803"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show that MAE is the mean of the absolute value of the differences\n",
    "df[\"differences\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3 Mean Squared Error (MSE)\n",
    "\n",
    "Mean of the square of the errors between actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2534678520824551"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual values</th>\n",
       "      <th>predicted values</th>\n",
       "      <th>differences</th>\n",
       "      <th>squared differences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>0.47700</td>\n",
       "      <td>0.493840</td>\n",
       "      <td>0.016840</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>0.45800</td>\n",
       "      <td>0.754940</td>\n",
       "      <td>0.296940</td>\n",
       "      <td>0.088173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>5.00001</td>\n",
       "      <td>4.928596</td>\n",
       "      <td>0.071414</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>2.18600</td>\n",
       "      <td>2.543160</td>\n",
       "      <td>0.357160</td>\n",
       "      <td>0.127563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>2.78000</td>\n",
       "      <td>2.331760</td>\n",
       "      <td>0.448240</td>\n",
       "      <td>0.200919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual values  predicted values  differences  squared differences\n",
       "20046        0.47700          0.493840     0.016840             0.000284\n",
       "3024         0.45800          0.754940     0.296940             0.088173\n",
       "15663        5.00001          4.928596     0.071414             0.005100\n",
       "20484        2.18600          2.543160     0.357160             0.127563\n",
       "9814         2.78000          2.331760     0.448240             0.200919"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize\n",
    "df[\"squared differences\"] = np.square(df[\"differences\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25346785208245565"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated by hand\n",
    "squared = np.square(df[\"differences\"])\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improving a Machine Learning Model (Experimentation)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When tuning hyperparameters, a new data split is used. Splits will look like:\n",
    "- Training split (70-80%)\n",
    "- Validation split (10-15%). These are used to tune hyperparameters\n",
    "- Testing split (10-15%)\n",
    "\n",
    "First predictions on a model are called **baseline predictions**. The first model you've made is called a **baseline model**.\n",
    "\n",
    "Ways to improve model from Data perspective:\n",
    "- Can we collect more data?\n",
    "- Can we improve our data? (more features, better features)\n",
    "\n",
    "Ways to improve model from the model's perspective:\n",
    "- Is there a better model we could use?\n",
    "- Could we improve the current model? (tuning hyperparameters)\n",
    "\n",
    "**Parameters**: a ML model finds parameter patterns in the data\n",
    "\n",
    "**Hyperparameters**: settings on the ML model that the user can adjust to (potentially) improve its ability to find parameters\n",
    "\n",
    "Three ways to adjust Hyperparameters:\n",
    "- By Hand\n",
    "- Randomly with RandomSearchCV\n",
    "- Exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# List model's Hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tuning Hyperparameters By Hand\n",
    "\n",
    "Make training, validation, and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See hyperparameters again\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adjusting the following:\n",
    "- `max_depth`\n",
    "- `max_features`\n",
    "- `min_samples_leaf`\n",
    "- `min_samples_split`\n",
    "- `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Make a reusable evaluation function to use on classification data\n",
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs y_preds labels\n",
    "    on a classification model\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2),\n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.81\n",
      "Recall: 0.88\n",
      "F1 Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Setup model and data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1) # shuffle all data\n",
    "\n",
    "# Separate into labels and targets\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Manually split data into train, validation, test splits\n",
    "train_split = round(0.7 * len(heart_disease_shuffled)) # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled)) # 15% of data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "# Train model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make baseline predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Adjust Hyperparameters by hand on a different classifier\n",
    "np.random.seed(42)\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=10) # tuned hyperparemeter\n",
    "clf2.fit(X_train, y_train)\n",
    "y_preds = clf2.predict(X_valid)\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 84.44%\n",
      "Precision: 0.85\n",
      "Recall: 0.88\n",
      "F1 Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Adjust Hyperparameters by hand on a third classifier\n",
    "np.random.seed(42)\n",
    "\n",
    "clf3 = RandomForestClassifier(n_estimators=100, max_depth=8) # tuned hyperparameters\n",
    "clf3.fit(X_train, y_train)\n",
    "y_preds = clf3.predict(X_valid)\n",
    "clf3_metrics = evaluate_preds(y_valid, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameter Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "# Import function\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create dictionary mapping hyperparameter name to values you'd like to try\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X (labels) and y (targets)\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate model\n",
    "clf = RandomForestClassifier(n_jobs=1) # n_jobs tells computer how much CPU resource to dedicate to training model. Default is 'None'\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,              # Estimator object\n",
    "                            param_distributions=grid,   # Dictionary of hyperparams and values to test\n",
    "                            n_iter=10,                  # Number of models to try with random choices of hyperparameters values from dictionary\n",
    "                            cv=5,                       # 5-fold cross validation\n",
    "                            verbose=2)                  \n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the best chosen parameters found by RandomizedSearchCV\n",
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Tuning Hyperparameters With GridSearchCV\n",
    "\n",
    "The difference between `GridSearchCV` and `RandomizedSearchCV` is that GridSearchCV will go through every possible combination of hyperparameters in the grid you've setup. It's kind of like a brute force method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_split': [2, 4, 6],\n",
       " 'min_samples_leaf': [1, 2, 4]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See grid of hyperparameters and values\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the search space of hyperparameters by only keeping values that are \"close\" to\n",
    "# what RandomizedSearchCV found to be the best ones\n",
    "grid_2 = {'n_estimators': [100, 200, 500],\n",
    "          'max_depth': [None],\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_split': [6],\n",
    "          'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X (labels) and y (targets)\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate model\n",
    "clf = RandomForestClassifier(n_jobs=1) # n_jobs tells computer how much CPU resource to dedicate to training model. Default is 'None'\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf,              # Estimator object\n",
    "                      param_grid=grid_2,          # Dictionary of hyperparams and values to test\n",
    "                      cv=5,                       # 5-fold cross validation\n",
    "                      verbose=2)                  \n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See best hyperparameters\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 78.69%\n",
      "Precision: 0.74\n",
      "Recall: 0.82\n",
      "F1 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with model found by GridSearchCV\n",
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the different models' metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                                \"clf_3\": clf3_metrics,\n",
    "                                \"random search\": rs_metrics,\n",
    "                                \"grid search\": gs_metrics})\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and Load a Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two ways to save and load machine learning models:\n",
    "1. Python's `pickle` module\n",
    "2. The `joblib` module (may be better for fitted scikit-learn models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(clf3, open(\"models/tuned_random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 95.08%\n",
      "Precision: 0.96\n",
      "Recall: 0.93\n",
      "F1 Score: 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.95, 'precision': 0.96, 'recall': 0.93, 'f1': 0.95}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Load a saved model\n",
    "loaded_pickle_model = pickle.load(open(\"models/tuned_random_forest_model_1.pkl\", \"rb\"))\n",
    "\n",
    "# Reset data splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Make some predictions with the loaded model\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/tuned_random_forest_model_2.joblib']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save model to a file\n",
    "dump(gs_clf, filename=\"models/tuned_random_forest_model_2.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 78.69%\n",
      "Precision: 0.74\n",
      "Recall: 0.82\n",
      "F1 Score: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79, 'precision': 0.74, 'recall': 0.82, 'f1': 0.78}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a saved model\n",
    "loaded_joblib_model = load(filename=\"models/tuned_random_forest_model_2.joblib\")\n",
    "\n",
    "# Make some predictions with the loaded model\n",
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Putting It All Together\n",
    "---\n",
    "\n",
    "Running through a standard Scikit-learn workflow again, but also using Scikit-learn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Make Colour  Odometer (KM)  Doors    Price\n",
       " 0   Honda  White        35431.0    4.0  15323.0\n",
       " 1     BMW   Blue       192714.0    5.0  19943.0\n",
       " 2   Honda  White        84714.0    4.0  28343.0\n",
       " 3  Toyota  White       154365.0    4.0  13434.0\n",
       " 4  Nissan   Blue       181577.0    3.0  14043.0,\n",
       " Make              object\n",
       " Colour            object\n",
       " Odometer (KM)    float64\n",
       " Doors            float64\n",
       " Price            float64\n",
       " dtype: object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data and peek at it\n",
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data.head(), data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps we want to do:\n",
    "1. Fill missing data\n",
    "2. Convert data to numbers\n",
    "3. Build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset={\"Price\"}, inplace=True)\n",
    "\n",
    "# Define different features and transformer pipeline\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Setup preprocessing steps (fill missing values, convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"door\", door_transformer, door_feature),\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a preprocessing and modeling pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to use `GridSearchCV` or `RandomizedSearchCV` with our `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.3s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.2s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value='missing',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('onehot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Make',\n",
       "                                                                          'Colour']),\n",
       "                                                                        ('door',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy='constant'))]),\n",
       "                                                                         ['Doors']),\n",
       "                                                                        ('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         ['Odometer '\n",
       "                                                                          '(KM)'])])),\n",
       "                                       ('model', RandomForestRegressor())]),\n",
       "             param_grid={'model__max_depth': [None, 5],\n",
       "                         'model__max_features': ['auto'],\n",
       "                         'model__min_samples_split': [2, 4],\n",
       "                         'model__n_estimators': [100, 1000],\n",
       "                         'preprocessor__num__imputer__strategy': ['mean',\n",
       "                                                                  'median']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Use GridSearchCV with our regression Pipeline\n",
    "#\n",
    "# The keys are drilling into steps of the Pipeline with __ separating different steps\n",
    "# For example, preprocessor__num__imputer__strategy goes to the `preprocessor` step of\n",
    "# the pipeline, goes to the `num` transformer step inside of that preprocessor, goes to \n",
    "# the `imputer`` step of that transformer, and then tries different strategies.\n",
    "#\n",
    "# The values are the different values of the step you want the GridSearchCV to try\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"auto\"],\n",
    "    \"model__min_samples_split\": [2, 4]\n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3339554263158365"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6bd038da01fb4dabe499472afbfe826077d6dcd05dd9fb6fce94b83e20e36b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
